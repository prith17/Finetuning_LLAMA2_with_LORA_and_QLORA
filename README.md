# Finetuning LLAMA2 with LORA and QLORA


## Overview:

This repository is dedicated to the process of finetuning the LLAMA2 model using LORA (Learning to Rank Answers) and QLORA (Question-based Learning to Rank Answers) techniques. LLAMA2, developed by Facebook AI, is a state-of-the-art large language model specifically designed for analyzing code. By leveraging LORA and QLORA, we aim to enhance LLAMA2's capabilities in code understanding, retrieval, and recommendation tasks.

## LLAMA2:

LLAMA2 is a powerful language model pretrained on a large corpus of code snippets and associated natural language descriptions. It has demonstrated remarkable performance in various code-related tasks such as code summarization, code completion, and code search.

## LORA (Learning to Rank Answers):

LORA is a technique that focuses on ranking the relevance of code snippets given a natural language query. By fine-tuning LLAMA2 with LORA, we aim to improve its ability to understand the context of code snippets within the context of a query, thus enhancing code retrieval accuracy.

## QLORA (Question-based Learning to Rank Answers):

QLORA builds upon LORA by incorporating the question-answer format commonly found in code-related queries. By fine-tuning LLAMA2 with QLORA, we aim to further refine its understanding of code by explicitly modeling the question-answer dynamics, resulting in more precise code snippet ranking.

